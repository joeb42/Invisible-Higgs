Final RNN:

1x GRU layer: 200 units, recurrent dropout = 0.5
1x Layer Norm
1x Dense 1 unit sigmoid

Trained using train test split seed of 5, train val split seed 42
Trained using new data
Batch size = 256
learning rate = 0.0005

Max significances are: 