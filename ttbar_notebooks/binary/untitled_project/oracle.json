{"ongoing_trials": {"tuner0": "1a9646026a1d5b3226913a19c1ba9c45"}, "hyperparameters": {"space": [{"class_name": "Int", "config": {"name": "mlp neurons per layer", "default": null, "conditions": [], "min_value": 50, "max_value": 200, "step": 25, "sampling": null}}, {"class_name": "Float", "config": {"name": "dropout rate", "default": 0.0, "conditions": [], "min_value": 0.0, "max_value": 0.4, "step": 0.05, "sampling": null}}, {"class_name": "Int", "config": {"name": "mlp layers", "default": null, "conditions": [], "min_value": 1, "max_value": 5, "step": 1, "sampling": null}}, {"class_name": "Int", "config": {"name": "combine position", "default": null, "conditions": [], "min_value": 1, "max_value": 1, "step": 1, "sampling": null}}, {"class_name": "Float", "config": {"name": "learning rate", "default": 1e-05, "conditions": [], "min_value": 1e-05, "max_value": 0.001, "step": 5e-06, "sampling": null}}, {"class_name": "Float", "config": {"name": "beta 1", "default": 0.9, "conditions": [], "min_value": 0.9, "max_value": 0.99, "step": 0.01, "sampling": null}}], "values": {"mlp neurons per layer": 50, "dropout rate": 0.0, "mlp layers": 1, "combine position": 1, "learning rate": 1e-05, "beta 1": 0.9}}, "seed": 7995, "seed_state": 8001, "tried_so_far": ["1b102cd67eeece13fed875bcf7516bf9"], "num_initial_points": 2, "alpha": 0.0001, "beta": 2.6}